
R Under development (unstable) (2024-10-01 r87205 ucrt) -- "Unsuffered Consequences"
Copyright (C) 2024 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ##  VT::11.10.2023 - this will render the output independent
> ##  from the version of the package
> suppressPackageStartupMessages(library(tclust))
> 
> require(tclust)
> require(MASS)
Loading required package: MASS
> #--- EXAMPLE 1 ------------------------------------------
> 
> set.seed(123)
> sig <- diag (2)
> cen <- rep (1,2)
> x <- rbind(MASS::mvrnorm(360, cen * 0,   sig),
+            MASS::mvrnorm(540, cen * 5,   sig * 6 - 2),
+            MASS::mvrnorm(100, cen * 2.5, sig * 50)
+            )
> 
> # Two groups and 10% trimming level
> (clus <- tclust(x, k = 2, alpha = 0.1, restr.fact = 8))
* Results for TCLUST algorithm: *
opt=HARD, trim = 0.1, k = 2
Restriction on: eigenvalues

Classification (trimmed points are indicated by 0 ):
   [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
  [38] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
  [75] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [112] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [149] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [186] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [223] 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [260] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [297] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [334] 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1
 [371] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [408] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [482] 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1
 [519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1
 [556] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [593] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [630] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [667] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [704] 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1
 [741] 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1
 [778] 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1
 [815] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [852] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [889] 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 2 0 2 0 1 0 0 0 0 0 1
 [926] 0 0 0 2 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0
 [963] 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 2 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 2 2 2
[1000] 1
Means:
         C 1        C 2
X 1 4.984845 0.02269302
X 2 4.929012 0.03215462

Trimmed objective function:  -3747.378 
Selected restriction factor: 8 
> 
> 
> # Three groups (one of them very scattered) and 0% trimming level
> (clus <- tclust(x, k = 3, alpha=0.0, restr.fact = 100))
* Results for TCLUST algorithm: *
opt=HARD, trim = 0, k = 3
Restriction on: eigenvalues

Classification (trimmed points are indicated by 0 ):
   [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
  [38] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
  [75] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [112] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [149] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [186] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [223] 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [260] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [297] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [334] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1
 [371] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [408] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [556] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [593] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [630] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [667] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [704] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [741] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [778] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [815] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [852] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [889] 1 1 1 1 1 1 1 1 1 1 1 1 3 3 1 3 3 3 3 1 1 3 3 1 3 2 2 3 2 3 1 3 3 3 3 3 1
 [926] 3 3 3 2 3 1 3 3 3 2 3 3 3 3 3 3 3 3 1 1 3 1 3 1 3 3 3 3 3 3 1 3 1 1 3 3 3
 [963] 3 3 3 3 3 3 3 1 3 3 1 3 3 3 3 3 1 3 2 3 1 3 3 1 1 3 1 3 3 3 1 1 3 3 2 2 2
[1000] 1
Means:
         C 1        C 2      C 3
X 1 4.889052 0.02676419 1.229842
X 2 5.055564 0.04517830 2.340643

Trimmed objective function:  -4731.715 
Selected restriction factor: 100 
> 
> 
> #--- EXAMPLE 2 ------------------------------------------
> data(geyser2)
> set.seed(123)
> (clus <- tclust(geyser2, k=3, alpha=0.03))
* Results for TCLUST algorithm: *
opt=HARD, trim = 0.03, k = 3
Restriction on: eigenvalues

Classification (trimmed points are indicated by 0 ):
  [1] 1 0 1 3 2 2 2 1 3 1 3 2 1 3 1 0 3 1 3 1 0 0 0 2 2 1 3 2 2 2 2 2 2 2 1 0 3
 [38] 1 3 2 1 3 1 3 2 2 1 3 1 3 2 1 3 1 3 2 1 3 2 1 3 1 3 1 3 2 2 1 3 2 1 3 2 1
 [75] 3 1 3 2 2 2 2 2 1 3 2 2 2 1 3 1 3 1 3 1 3 2 2 1 3 1 3 1 3 2 1 3 1 3 2 2 1
[112] 3 2 1 3 1 3 1 3 1 3 2 1 3 2 1 3 1 3 1 3 1 2 1 3 1 3 1 3 2 1 3 2 2 1 3 1 3
[149] 1 3 2 1 3 2 2 2 2 1 3 1 3 1 3 2 2 1 3 1 3 1 0 3 2 2 2 2 1 3 2 1 3 2 2 1 3
[186] 2 1 3 1 3 1 3 2 2 2 2 2 1 3 1 3 2 1 3 1 3 2 1 3 1 3 1 3 2 2 1 3 1 3 1 3 1
[223] 3 2 2 2 2 2 2 2 1 3 1 3 1 0 3 2 1 3 1 3 2 2 2 1 3 1 3 1 3 2 2 2 2 2 2 1 3
[260] 2 2 1 3 1 0 3 2 1 3 1 3
Means:
                              C 1      C 2      C 3
Eruption length          4.340629 4.199207 2.020919
Previous eruption length 2.026584 4.093862 4.501721

Trimmed objective function:  -441.7624 
Selected restriction factor: 12 
> plot(clus)
>  
> #--- EXAMPLE 3 ------------------------------------------
> data (M5data)
> set.seed(123)
> x <- M5data[, 1:2]
> 
> (clus.a <- tclust(x, k=3, alpha=0.1, restr.fact=1,
+                   restr = "eigen", equal.weights=TRUE))
* Results for TCLUST algorithm: *
opt=HARD, trim = 0.1, k = 3
Restriction on: eigenvalues

Classification (trimmed points are indicated by 0 ):
   [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
  [38] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
  [75] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [112] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [149] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [186] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [223] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [260] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [297] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [334] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 2 3 1 2 3 3 1
 [371] 3 3 0 3 3 3 3 3 3 2 2 3 3 3 3 3 1 2 3 3 3 3 3 3 0 3 2 3 3 3 3 3 2 0 3 3 3
 [408] 3 3 2 3 3 3 3 3 2 2 3 1 3 3 1 2 3 3 3 3 3 2 3 2 3 1 2 1 3 3 3 3 2 3 3 2 1
 [445] 2 0 3 3 3 3 3 1 3 0 3 3 2 3 3 3 3 2 3 3 2 2 2 3 3 3 2 3 3 2 2 2 3 2 3 3 2
 [482] 2 3 3 3 3 3 3 3 3 3 3 3 2 1 2 3 3 3 3 3 3 3 3 3 1 3 3 2 0 3 3 3 0 0 2 3 3
 [519] 3 3 3 3 1 3 3 1 3 2 3 3 1 3 3 3 3 2 2 2 2 3 2 2 3 2 3 2 3 3 3 3 3 3 3 3 3
 [556] 3 3 3 2 3 3 3 1 3 3 3 2 1 3 3 3 2 1 3 2 3 3 0 2 3 3 2 3 3 0 3 3 3 3 1 3 3
 [593] 1 3 3 3 2 2 3 3 3 3 3 3 3 2 3 2 3 3 3 3 1 3 3 3 3 3 3 2 2 1 3 3 3 3 3 1 3
 [630] 3 3 2 3 3 2 3 3 3 3 2 3 0 3 3 3 2 2 3 3 3 2 0 1 3 3 3 3 3 3 2 3 3 0 3 3 3
 [667] 3 3 3 3 3 3 0 3 0 3 2 3 2 3 3 1 3 3 3 3 3 3 2 3 3 0 2 2 2 3 3 3 3 3 3 3 2
 [704] 3 2 1 3 2 3 3 0 3 3 2 3 3 3 2 3 3 3 2 3 0 2 2 3 2 0 3 3 3 3 2 3 3 3 2 2 1
 [741] 2 3 3 2 0 3 3 3 3 3 3 3 3 3 3 1 3 3 2 3 2 3 3 3 2 3 3 3 3 3 3 3 3 3 2 2 3
 [778] 3 3 3 2 3 3 2 3 3 3 0 3 3 2 1 3 3 2 3 3 2 3 1 2 3 0 3 2 3 2 3 3 2 3 0 3 3
 [815] 3 3 3 3 3 3 3 3 3 0 0 3 3 2 3 3 2 3 2 2 1 3 2 3 3 2 2 3 3 2 2 2 2 3 3 3 3
 [852] 3 3 3 3 0 2 3 3 3 3 3 2 0 1 3 2 2 3 3 3 3 3 2 3 3 3 3 3 3 2 2 3 2 3 3 1 3
 [889] 3 3 2 3 3 2 3 3 3 3 3 2 3 3 3 2 3 2 3 2 2 0 3 2 2 2 3 2 3 3 3 3 0 3 3 3 2
 [926] 3 3 3 2 3 1 3 2 3 2 3 3 3 3 2 3 1 3 3 3 3 3 3 3 2 3 3 0 2 2 3 2 2 3 1 3 2
 [963] 3 2 2 3 3 3 2 3 3 3 3 0 3 3 3 2 3 3 0 0 2 0 0 3 1 3 3 3 3 2 2 3 3 3 3 1 3
[1000] 2 3 3 3 1 2 3 2 3 2 3 2 1 1 3 3 3 3 3 3 3 3 2 3 2 3 3 3 2 3 3 3 3 3 2 2 2
[1037] 2 3 3 2 2 3 3 3 3 2 3 3 1 3 2 3 3 3 0 1 3 3 2 3 3 3 3 3 3 3 3 0 3 3 3 3 3
[1074] 2 3 2 3 3 3 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1
[1111] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1148] 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1185] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1222] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1259] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1296] 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1333] 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1370] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1407] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1444] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1481] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1
[1518] 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1555] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1592] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1629] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1666] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1703] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1740] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1777] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 2 0 1 0 0 0 0 0 0
[1814] 0 2 0 0 1 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 0 0 1 0 2 0 0 0 2 0 0 2 0 0 0 0
[1851] 0 1 0 0 0 0 0 0 0 2 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0
[1888] 2 1 2 0 0 0 0 0 0 1 0 0 0 0 0 0 2 2 1 0 0 0 0 0 0 0 2 0 0 0 0 1 1 2 0 0 0
[1925] 0 1 1 1 0 1 1 1 0 0 0 1 0 2 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 2 0 0 1 0 0
[1962] 0 0 2 0 0 0 0 0 0 2 0 1 0 0 0 0 0 1 0 0 0 0 0 2 0 1 0 0 0 0 0 0 0 0 0 0 0
[1999] 0 0
Means:
        C 1      C 2       C 3
x -7.777440 0.331593 10.461001
y -8.496549 7.317294 -1.089452

Trimmed objective function:  -23391.1 
Selected restriction factor: 1 
> (clus.b <- tclust(x, k=3, alpha=0.1, restr.fact=50,
+                     restr="eigen", equal.weights=TRUE))
* Results for TCLUST algorithm: *
opt=HARD, trim = 0.1, k = 3
Restriction on: eigenvalues

Classification (trimmed points are indicated by 0 ):
   [1] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
  [38] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
  [75] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
 [112] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
 [149] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
 [186] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
 [223] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
 [260] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
 [297] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
 [334] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2
 [371] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [408] 2 2 2 2 2 2 2 2 2 3 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 1 3 2 2 2 2 2 2 2 2 2 1
 [445] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 3 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2
 [482] 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2
 [519] 2 2 2 2 1 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 0 2 3 3 2 3 2 2 2 2 2 2 2 2 2 2 2
 [556] 2 2 2 3 2 2 2 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 0 2 2 2 2 2 2 0 2 2 2 2 2 2 2
 [593] 1 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2
 [630] 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [667] 2 2 2 2 2 2 2 2 0 2 2 2 3 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2
 [704] 2 2 1 2 2 2 2 0 2 2 0 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 1
 [741] 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 0 2 2 2 3 2 2 2 2 2 2 2 2 2 2 3 2
 [778] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 0 2 2
 [815] 2 2 2 2 2 2 2 2 2 0 0 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [852] 2 2 2 2 2 3 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 3 2 2 2 2 2 2 2
 [889] 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 3 2 2 2 2 0 2 2 2 3
 [926] 2 2 2 2 2 1 2 3 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 0
 [963] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 1 2 2 2 2 3 2 2 2 2 2 2 2
[1000] 2 2 2 2 1 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 0 2 2 2 2 2 2 2 2 2 0 2 2
[1037] 3 2 2 2 2 2 2 2 2 2 2 2 1 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2
[1074] 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1111] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1148] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1185] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1222] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1259] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1296] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1333] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1370] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1407] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1444] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1481] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1
[1518] 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1555] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1592] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1629] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1666] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1703] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1
[1740] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1777] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0
[1814] 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 2 0 0 0 0 0 0
[1851] 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0
[1888] 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0
[1925] 0 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0
[1962] 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 2 0 0 0 0 0
[1999] 0 0
Means:
        C 1        C 2        C 3
x -7.985364  8.8962516 0.07801393
y -8.372378 -0.3114254 7.90622006

Trimmed objective function:  -22781.32 
Selected restriction factor: 50 
> (clus.c <- tclust(x, k=3, alpha=0.1, restr.fact=1,
+                     restr="deter", equal.weights=TRUE))
* Results for TCLUST algorithm: *
opt=HARD, trim = 0.1, k = 3
Restriction on: determinants

Classification (trimmed points are indicated by 0 ):
   [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
  [38] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
  [75] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [112] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [149] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [186] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [223] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [260] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [297] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [334] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 3 2 3 3 2 3 3 3
 [371] 3 3 0 3 3 3 3 2 3 2 2 3 3 3 3 3 1 2 3 3 3 3 3 3 0 3 2 3 3 3 3 3 2 0 3 3 3
 [408] 3 3 2 3 3 3 3 3 3 2 3 3 3 3 1 2 3 3 3 3 3 2 3 2 3 1 2 3 3 3 3 3 2 3 2 2 1
 [445] 2 0 3 3 3 3 3 1 3 0 3 3 3 3 3 2 3 2 3 3 2 2 2 3 3 2 2 3 3 2 2 2 3 2 2 3 2
 [482] 2 3 3 3 3 3 3 3 2 3 3 3 2 3 2 3 3 3 2 3 3 3 3 3 3 3 3 2 2 3 3 3 0 3 2 3 3
 [519] 3 3 3 3 1 3 3 1 3 3 3 3 3 3 3 3 3 2 2 3 2 3 2 2 3 2 3 2 3 2 3 3 3 2 3 3 2
 [556] 3 2 3 2 3 3 3 1 3 3 3 2 3 3 0 3 2 1 3 2 3 3 0 2 3 3 3 3 2 0 3 3 3 0 3 3 2
 [593] 1 3 3 2 2 2 3 3 3 3 3 2 3 2 3 2 3 3 3 3 1 3 3 3 3 3 3 2 3 1 3 3 3 3 3 3 3
 [630] 3 3 2 3 3 2 3 3 3 3 2 3 0 3 3 3 2 2 3 3 3 3 0 3 3 3 3 3 3 3 3 3 3 0 3 3 3
 [667] 3 3 3 3 3 3 0 2 0 3 2 3 2 3 3 1 3 3 3 3 3 2 2 3 3 0 3 2 2 3 3 2 2 3 3 3 2
 [704] 2 2 1 3 2 2 3 0 3 3 2 3 2 3 2 3 3 3 2 3 0 2 2 3 2 0 3 3 2 3 2 3 2 2 2 2 1
 [741] 2 3 3 2 0 3 3 3 3 3 3 3 3 3 3 1 3 3 2 3 2 3 3 3 2 3 3 2 3 3 3 3 3 3 2 2 3
 [778] 3 3 3 2 3 3 2 3 3 3 0 3 3 2 1 3 2 2 3 3 2 3 3 2 2 3 3 2 3 2 3 3 2 3 0 0 3
 [815] 3 3 3 3 3 3 2 3 3 0 0 2 3 2 3 3 3 3 2 2 1 3 2 3 2 2 2 3 3 2 0 2 2 3 3 3 3
 [852] 3 3 3 3 0 2 3 3 3 3 3 2 0 1 3 2 2 3 3 3 3 3 2 3 3 3 3 3 2 2 2 3 2 3 3 3 3
 [889] 3 3 2 2 3 2 3 3 2 0 3 2 3 3 2 2 3 2 3 2 2 0 3 2 2 3 3 2 3 3 3 3 0 3 3 3 2
 [926] 2 3 2 2 3 1 3 2 3 2 3 3 3 3 2 3 3 2 3 3 3 3 2 3 2 3 2 3 2 2 3 2 2 3 1 0 2
 [963] 3 2 2 3 3 3 2 3 3 3 3 0 3 3 3 2 3 0 0 0 3 1 0 3 1 3 3 2 3 2 2 3 3 3 3 3 3
[1000] 2 3 3 3 1 2 3 2 2 2 3 2 1 1 3 3 3 3 3 2 3 3 2 3 2 3 2 3 2 3 3 3 3 3 2 2 2
[1037] 2 3 3 2 3 3 3 3 2 2 3 3 1 3 2 3 3 3 0 2 3 2 2 3 3 3 3 3 2 3 3 0 3 3 2 3 3
[1074] 2 3 2 3 2 3 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1111] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1148] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1185] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1222] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1259] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1296] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1333] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1370] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1407] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1444] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1481] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1
[1518] 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1555] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1592] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1629] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1666] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1703] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1
[1740] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1777] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 2 0 0 0 1 0 0 0 0 0 0
[1814] 0 0 0 0 1 0 0 0 0 0 0 0 2 0 1 0 0 0 1 2 0 0 0 0 0 2 0 1 0 2 0 0 2 0 0 0 0
[1851] 0 1 0 1 0 1 0 0 0 2 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 2 0 0 1 0 0
[1888] 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 1 0 2 0 0 0 0 0 1 2 0 0 2
[1925] 0 1 1 1 0 0 0 1 0 0 0 1 0 2 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 2 0 0 1 0 0
[1962] 0 0 2 0 0 0 0 0 0 2 0 0 0 1 0 0 0 1 0 0 0 0 0 2 0 1 0 0 0 0 0 0 0 0 0 0 0
[1999] 0 0
Means:
        C 1      C 2       C 3
x -7.953569 1.038084  9.960540
y -8.346524 7.294284 -1.867793

Trimmed objective function:  -23210.25 
Selected restriction factor: 1 
> (clus.d <- tclust(x, k=3, alpha=0.1, restr.fact=50,
+                     restr="eigen", equal.weights=FALSE))
* Results for TCLUST algorithm: *
opt=HARD, trim = 0.1, k = 3
Restriction on: eigenvalues

Classification (trimmed points are indicated by 0 ):
   [1] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
  [38] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
  [75] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
 [112] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
 [149] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
 [186] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
 [223] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
 [260] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
 [297] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
 [334] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2
 [371] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [408] 2 2 2 2 2 2 2 2 2 3 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 1 3 2 2 2 2 2 2 2 2 2 1
 [445] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [482] 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2
 [519] 2 2 2 2 1 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 0 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [556] 2 2 2 3 2 2 2 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 0 2 2 2 2 2 2 0 2 2 2 2 2 2 2
 [593] 1 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2
 [630] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [667] 2 2 2 2 2 2 2 2 0 2 2 2 3 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2
 [704] 2 2 1 2 2 2 2 0 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 1
 [741] 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 0 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2
 [778] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 0 2 2
 [815] 2 2 2 2 2 2 2 2 2 0 0 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [852] 2 2 2 2 2 3 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2
 [889] 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 0 2 2 2 3
 [926] 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0
 [963] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2
[1000] 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 0 2 2 2 2 2 2 2 2 2 0 2 2
[1037] 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2
[1074] 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1111] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1148] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1185] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1222] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1259] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1296] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1333] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1370] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1407] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1444] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1481] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1
[1518] 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1555] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1592] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1629] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1666] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1703] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1
[1740] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[1777] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0
[1814] 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
[1851] 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0
[1888] 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0
[1925] 0 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0
[1962] 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 2 0 0 0 0 0
[1999] 0 0
Means:
        C 1        C 2        C 3
x -8.001393  8.6605632 0.04397704
y -8.360821 -0.1056621 7.92670007

Trimmed objective function:  -11200.97 
Selected restriction factor: 50 
> 
> #--- EXAMPLE 4 ------------------------------------------
> data (swissbank)
> set.seed(123)
> # Two clusters and 8% trimming level
> (clus <- tclust(swissbank, k = 2, alpha = 0.08, restr.fact = 50))
* Results for TCLUST algorithm: *
opt=HARD, trim = 0.08, k = 2
Restriction on: eigenvalues

Classification (trimmed points are indicated by 0 ):
  [1] 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [38] 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1
 [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 1
[112] 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 0
[149] 2 2 2 2 2 2 2 2 2 2 2 0 0 0 2 2 2 2 0 0 2 2 0 2 2 2 2 2 2 2 2 0 2 0 2 2 2
[186] 2 0 2 2 2 2 0 2 0 2 2 2 2 2 2
Means:
                C 1       C 2
Length   215.001010 214.78000
Ht_Left  129.939394 130.26706
Ht_Right 129.724242 130.18353
IF_Lower   8.294949  10.84588
IF_Upper  10.191919  11.09882
Diagonal 141.483838 139.62941

Trimmed objective function:  -542.7962 
Selected restriction factor: 50 
> 
> # Three clusters and 0% trimming level
> (clus <- tclust(swissbank, k = 3, alpha = 0.0, restr.fact = 110))
* Results for TCLUST algorithm: *
opt=HARD, trim = 0, k = 3
Restriction on: eigenvalues

Classification (trimmed points are indicated by 0 ):
  [1] 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1
 [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3
[112] 2 2 2 2 3 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 3
[149] 2 2 2 2 2 2 2 2 2 2 2 3 3 3 2 2 2 2 3 3 2 2 3 2 2 2 2 2 2 2 2 3 2 3 2 2 2
[186] 2 3 2 2 2 2 3 2 3 2 2 2 2 2 2
Means:
               C 1       C 2        C 3
Length   214.97143 214.78095 215.022222
Ht_Left  129.92959 130.26429 130.500000
Ht_Right 129.70102 130.17976 130.305556
IF_Lower   8.30102  10.85714   8.777778
IF_Upper  10.16224  11.10833  11.172222
Diagonal 141.54184 139.62381 138.733333

Trimmed objective function:  -627.1889 
Selected restriction factor: 110 
> 
> 
> #--- EXAMPLE 5 ------------------------------------------
> data (flea)
> # Three clusters and 8% trimming level
> set.seed(123)
> (clus <- tclust(flea[, 1:6], k = 3, alpha = 0.08, restr.fact = 50))
* Results for TCLUST algorithm: *
opt=HARD, trim = 0.08, k = 3
Restriction on: eigenvalues

Classification (trimmed points are indicated by 0 ):
 [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
[39] 3 3 0 3 3 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1
Means:
            C 1       C 2    C 3
tars1 201.14815 183.09524 137.30
tars2 119.88889 129.61905 123.25
head   48.88889  51.23810  51.20
aede1 125.14815 146.19048 138.00
aede2  14.11111  14.09524  10.20
aede3  82.40741 104.85714 106.25

Trimmed objective function:  -1167.023 
Selected restriction factor: 50 
> ##  adjustedRand(clus$cluster, as.integer(flea[,7]))
> 
> # Three clusters and 0% trimming level
> set.seed(123)
> (clus <- tclust(flea[,1:6], k = 3, alpha = 0.0, restr.fact = 110))
* Results for TCLUST algorithm: *
opt=HARD, trim = 0, k = 3
Restriction on: eigenvalues

Classification (trimmed points are indicated by 0 ):
 [1] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
[39] 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1
Means:
            C 1       C 2       C 3
tars1 201.30000 138.22727 183.50000
tars2 119.66667 125.09091 128.68182
head   48.96667  51.59091  51.00000
aede1 124.46667 138.27273 145.45455
aede2  14.33333  10.09091  14.04545
aede3  80.70000 106.59091 104.18182

Trimmed objective function:  -1289.658 
Selected restriction factor: 110 
> ##  adjustedRand(clus$cluster, as.integer(flea[,7]))
> 
> # Three clusters and 10% trimming level
> set.seed(123)
> (clus <- tclust(flea[,1:6], k = 3, alpha = 0.1, restr="deter", restr.fact = 110))
* Results for TCLUST algorithm: *
opt=HARD, trim = 0.1, k = 3
Restriction on: determinants

Classification (trimmed points are indicated by 0 ):
 [1] 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 0 2 2 0 2 0 2 3 2 2 2 0 0 2 2
[39] 2 2 0 2 2 1 1 1 3 1 1 1 1 1 1 3 1 1 3 1 1 3 3 1 1 1 1 1 1 0 1 1 1 1 1 1
Means:
            C 1      C 2       C 3
tars1 193.20000 137.2667 192.33333
tars2 124.06667 124.0000 121.33333
head   49.95556  51.6000  48.83333
aede1 133.93333 138.2667 128.66667
aede2  14.24444  10.0000  13.33333
aede3  91.64444 106.0000  89.00000

Trimmed objective function:  -1133.875 
Selected restriction factor: 110 
> ##  adjustedRand(clus$cluster, as.integer(flea[,7]))
> 
> ##### Discriminant Factor Analysis for tclust Objects ####################
> sig <- diag (2)
> cen <- rep (1, 2)
> x <- rbind(MASS::mvrnorm(360, cen * 0,   sig),
+ 	       MASS::mvrnorm(540, cen * 5,   sig * 6 - 2),
+ 	       MASS::mvrnorm(100, cen * 2.5, sig * 50)
+ )
> (clus.1 <- tclust(x, k = 2, alpha = 0.1, restr.fact = 12))
* Results for TCLUST algorithm: *
opt=HARD, trim = 0.1, k = 2
Restriction on: eigenvalues

Classification (trimmed points are indicated by 0 ):
   [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2
  [38] 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
  [75] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [112] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2
 [149] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [186] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [223] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [260] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [297] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [334] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1
 [371] 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [408] 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1
 [445] 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1
 [519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1
 [556] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [593] 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1
 [630] 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [667] 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [704] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [741] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1
 [778] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1
 [815] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [852] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [889] 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 2 0 1 0 0 0 0
 [926] 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 2 0 1 0 2 0 0 1 0
 [963] 0 2 0 0 0 0 0 0 0 1 0 0 0 1 2 1 2 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0
[1000] 0
Means:
         C 1         C 2
X 1 4.946096 -0.01986877
X 2 4.969820 -0.03183682

Trimmed objective function:  -3736.514 
Selected restriction factor: 12 
> 
> (clus.2 <- tclust(x, k = 3, alpha = 0.1, restr.fact = 1))
* Results for TCLUST algorithm: *
opt=HARD, trim = 0.1, k = 3
Restriction on: eigenvalues

Classification (trimmed points are indicated by 0 ):
   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
  [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [112] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [260] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [334] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 3 3 2 3 2 3 2 3
 [371] 2 2 2 2 3 0 2 2 2 2 2 2 3 3 3 3 2 2 3 2 3 2 3 2 3 2 2 3 2 3 3 2 3 3 2 3 2
 [408] 2 3 0 2 2 3 3 2 2 2 2 2 0 2 3 3 2 2 3 3 3 2 2 2 2 3 2 3 0 3 2 2 2 3 2 2 2
 [445] 2 3 3 2 2 2 2 3 0 2 3 3 3 3 3 2 0 3 2 2 2 0 2 3 2 2 2 2 3 2 2 3 3 3 3 2 3
 [482] 2 2 0 3 2 2 3 2 3 3 3 2 2 2 2 2 3 3 2 3 2 2 3 3 2 3 3 1 3 2 3 2 2 3 3 3 3
 [519] 3 3 2 3 2 3 2 3 2 2 0 2 3 2 2 2 3 3 2 2 1 2 2 2 2 2 2 2 3 2 3 2 3 0 3 2 2
 [556] 2 3 2 3 2 2 2 2 2 2 2 2 2 3 2 2 2 3 3 2 0 2 3 3 3 2 2 2 3 2 2 2 2 2 3 2 3
 [593] 3 3 2 2 2 2 2 2 2 3 2 0 2 3 2 3 2 3 2 2 3 3 2 2 2 2 3 0 3 3 2 2 3 2 2 3 3
 [630] 3 3 2 2 2 2 2 2 2 2 2 0 3 3 3 3 2 2 3 0 3 2 2 3 2 3 2 2 3 2 3 2 2 0 2 3 3
 [667] 2 3 2 3 2 2 3 2 2 3 3 3 0 2 3 3 2 2 2 3 3 2 2 2 3 3 2 2 3 2 2 3 0 2 2 2 2
 [704] 2 3 2 2 3 2 3 2 2 2 2 3 3 2 2 2 2 2 2 2 3 3 2 2 2 2 3 3 2 3 2 3 2 3 2 2 2
 [741] 3 2 2 2 3 3 3 2 2 2 2 2 3 2 3 3 2 3 3 2 3 2 2 2 3 3 3 2 3 2 2 0 2 2 3 2 2
 [778] 3 3 2 0 3 2 2 2 2 2 2 3 2 2 3 3 2 3 0 3 2 2 2 3 0 2 3 3 2 3 2 2 3 3 2 3 2
 [815] 3 2 2 3 3 2 3 2 3 3 2 2 2 2 2 2 3 3 3 3 2 2 2 3 2 3 3 3 3 2 2 2 2 2 2 2 3
 [852] 3 2 3 2 2 2 3 3 2 3 2 3 0 3 3 2 3 2 3 3 3 3 3 3 3 3 3 3 2 3 2 2 3 2 2 2 3
 [889] 3 2 3 3 3 3 2 3 0 2 3 3 0 2 0 1 0 0 0 3 0 0 0 0 0 2 0 0 0 0 1 0 2 0 0 1 1
 [926] 2 0 0 1 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 1 0 2 0 1 0 0 0 0
 [963] 0 1 0 0 0 0 0 0 0 3 0 0 0 3 1 2 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 2 0 2 0 0
[1000] 0
Means:
            C 1      C 2      C 3
X 1  0.02094189 5.997484 3.534748
X 2 -0.04345996 3.945200 6.436588

Trimmed objective function:  -3839.642 
Selected restriction factor: 1 
>   ##  restr.fact and k are chosen improperly for pointing out the
>   ##    difference in the plot of DiscrFact
> 
> (dsc.1 <- DiscrFact(clus.1))
Mean overall discriminant factor: -20.03477 
Mean discriminant factor per cluster:
        O         1         2 
-16.02019 -25.05581 -13.68156 
30 decisions are considered as doubtful
> (dsc.2 <- DiscrFact(clus.2))
Mean overall discriminant factor: -11.26542 
Mean discriminant factor per cluster:
         O          1          2          3 
-22.939002 -17.901155  -4.610035  -4.004185 
192 decisions are considered as doubtful
> 
> 
> ########## Classification Trimmed Likelihood Curves  ################### 
> 
> ## Do not run - it takes too long and can show differences on some
> ##  architectures due to the random numbers.
> ##
> #--- EXAMPLE 1 ------------------------------------------
> 
> if(FALSE) {
+     sig <- diag (2)
+     cen <- rep (1, 2)
+     x <- rbind(MASS::mvrnorm(108, cen * 0,   sig),
+     	       MASS::mvrnorm(162, cen * 5,   sig * 6 - 2),
+     	       MASS::mvrnorm(30, cen * 2.5, sig * 50)
+     )
+ 
+     (ctl <- ctlcurves(x, k = 1:4))
+ }
> 
> #--- EXAMPLE 2 ------------------------------------------
> if(FALSE) {
+     data (geyser2)
+     (ctl <- ctlcurves(geyser2, k = 1:5))
+ }
> 
> ## External indices: Rand, etc ...
> ##  1. randindex with the contingency table as input.
> T <- matrix(c(1, 1, 0, 1, 2, 1, 0, 0, 4), nrow=3)
> (ARI <- randIndex(T))
$AR
[1] 0.3125734

$RI
[1] 0.7111111

$MI
[1] 0.2888889

$HI
[1] 0.4222222

> (FM <- FowlkesMallowsIndex(T))
$ABk
[1] 0.3128799

$Bk
[1] 0.5188745

$EBk
[1] 0.2997942

$VarBk
[1] 0.01115259

> 
> ##  2. randindex with the two vectors as input.
> c <- matrix(c(1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3), ncol=2, byrow=TRUE)
> ## c1 = numeric vector containing the labels of the first partition
> c1 <- c[,1]
> ## c2 = numeric vector containing the labels of the second partition
> c2 <- c[,2]
> 
> (ARI <- randIndex(c1, c2))
$AR
[1] 0.3125734

$RI
[1] 0.7111111

$MI
[1] 0.2888889

$HI
[1] 0.4222222

> (FM <- FowlkesMallowsIndex(c1, c2))
$ABk
[1] 0.3128799

$Bk
[1] 0.5188745

$EBk
[1] 0.2997942

$VarBk
[1] 0.01115259

> 
> ##  3. Compare ARI for iris data (true classification against tclust classification)
> library(tclust)
> c1 <- iris$Species  # first partition c1 is the true partition
> out <- tclust(iris[, 1:4], k=3, alpha=0, restr.fact=100)
> c2 <- out$cluster   # second partition c2 is the output of tclust clustering procedure
> 
> (ARI <- randIndex(c1, c2))
$AR
[1] 0.7183576

$RI
[1] 0.873736

$MI
[1] 0.126264

$HI
[1] 0.747472

> (FM <- FowlkesMallowsIndex(c1, c2))
$ABk
[1] 0.7188372

$Bk
[1] 0.8140886

$EBk
[1] 0.3387766

$VarBk
[1] 3.73991e-05

> 
> ##  4. Compare ARI for iris data (exclude unassigned units from tclust).
> 
> c1 <- iris$Species      # first partition c1 is the true partition
> out <- tclust(iris[,1:4], k=3, alpha=0.1, restr.fact=100)
> c2 <- out$cluster       #  second partition c2 is the output of tclust clustering procedure
> 
> ## Units inside c2 which contain number 0 are referred to trimmed observations
> noisecluster <- 0
> (ARI <- randIndex(c1, c2, noisecluster=0))
$AR
[1] 0.6812234

$RI
[1] 0.8518519

$MI
[1] 0.1481481

$HI
[1] 0.7037037

> (FM <- FowlkesMallowsIndex(c1, c2, noisecluster=0))
$ABk
[1] 0.6854033

$Bk
[1] 0.7992836

$EBk
[1] 0.3619881

$VarBk
[1] 4.237826e-05

> 
> 
> proc.time()
   user  system elapsed 
  42.07    8.67   47.14 
